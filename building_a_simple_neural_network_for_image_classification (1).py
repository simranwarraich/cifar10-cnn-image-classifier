# -*- coding: utf-8 -*-
"""Building a Simple Neural Network for Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cculIxtDb9qfzqF9cJ-8b1QGUHIWT9Bu

# 1. Importing Libraries:
"""

import tensorflow as tf #to define and train our neural network for image classification.
from tensorflow.keras import layers, models, datasets #simple and intuitive interface for building neural networks.
import matplotlib.pyplot as plt #to visualize the images and the training process

"""# 2. Loading and Preprocessing the Dataset:

"""

# Load the CIFAR-10 dataset and split it into training and test sets
(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()

# Normalize the pixel values to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

# Print the shapes of the datasets
print("Training data shapes:", x_train.shape, y_train.shape)
print("Test data shapes:", x_test.shape, y_test.shape)

# Visualize data by plotting images
fig, ax = plt.subplots(5, 5) # Create a 5x5 grid of subplots
k = 0

for i in range(5):
    for j in range(5):
        ax[i][j].imshow(x_train[k], aspect='auto') # Plot the k-th image in the grid
        k += 1

plt.show()

"""# 3. Defining the Neural Network Architecture:"""

# Define the neural network architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)), # Convolutional layer with 32 filters, kernel size 3x3, ReLU activation, and input shape (32, 32, 3)
    layers.MaxPooling2D((2, 2)), # Max pooling layer with 2x2 pool size
    layers.Conv2D(64, (3, 3), activation='relu'), # Convolutional layer with 64 filters, kernel size 3x3, and ReLU activation
    layers.MaxPooling2D((2, 2)), # Max pooling layer with 2x2 pool size
    layers.Conv2D(64, (3, 3), activation='relu'), # Convolutional layer with 64 filters, kernel size 3x3, and ReLU activation
    layers.Flatten(), # Flatten the output of the convolutional layers to feed into the dense layers
    layers.Dense(64, activation='relu'), # Fully connected layer with 64 units and ReLU activation
    layers.Dense(10) # Output layer with 10 units (one for each class)
])

"""# 4. Compiling the Model:


"""

# Compile the model
model.compile(optimizer='adam', # Use the Adam optimizer
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # Use sparse categorical cross-entropy loss
              metrics=['accuracy']) # can also use categorical_accuracy

"""# 5.Training the Model:

"""

# Train the model
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))# Train for 10 epochs, using the test data for validation

"""# 6. Evaluating the Model:


"""

# Evaluate the model
test_loss, test_acc  = model.evaluate(x_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc}") # Print the test accuracy

"""# 7. Plotting the Training History:


"""

# Plot training history
plt.plot(history.history['accuracy'], label='accuracy') # Plot the training accuracy
plt.plot(history.history['val_accuracy'], label = 'val_accuracy') # Plot the validation accuracy
plt.xlabel('Epoch') # Set the x-axis label
plt.ylabel('Accuracy') # Set the y-axis label
plt.legend(loc='lower right') # Add a legend
plt.show()

"""# 8. Testing the Model"""

import numpy as np
labels = '''airplane automobile bird cat deer dog frog horse ship truck'''.split() # Define a list of labels for the CIFAR-10 classes
image_number = 80 # Select an image from the test set
plt.imshow(x_test[image_number]) # Show the image
n = np.array(x_test[image_number]) # Convert the image to a NumPy array
p = n.reshape(1, 32, 32, 3) #  Reshape the image for input to the model
predicted_label = labels[model.predict(p).argmax()] # Get the predicted label
y_train, y_test = y_train.flatten(), y_test.flatten() # Flatten the label arrays
original_label = labels[y_test[image_number]] # Get the original label

# Print the original and predicted labels
print("Original label is {} and predicted label is {}".format(
	original_label, predicted_label))